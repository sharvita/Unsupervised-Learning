{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4580/5580 - Data Science ‚Äì Fall 2020\n",
    "## Lab 9: Unsupervised Learning\n",
    "\n",
    "#### **Student Full Name**: Sharvita Paithankar\n",
    "\n",
    "#### **Student ID**: 108172438\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you Begin:\n",
    "As with Lab 8, this lab will require using the `tensorflow` deep learning library. In the previous lab, you created a virtual environment called `tf` that contained tensorflow and some dependencies.\n",
    "\n",
    "For this lab, we will also need some new dependencies. Follow the steps below to install the new dependencies to your `tf` conda environment.\n",
    "\n",
    "First, activate your `tf` environment using `conda activate tf`.\n",
    "\n",
    "![Activate conda tf environment](imgs/activate_tf.png)\n",
    "\n",
    "This lab requires two new dependencies: \n",
    "* `seaborn` - A plotting library built on `matplotlib`.\n",
    "* `scikit-learn` - The scikit-learn packages. We have used this package before, but not from the `tf` environment.\n",
    "\n",
    "You can install both dependencies with a single line of code:\n",
    "\n",
    "![install packages](imgs/install_packages.png)\n",
    "\n",
    "Finally, run `jupyter notebook` or `jupyter lab` to proceed with the assignment.\n",
    "\n",
    "![run jupyter](imgs/run_jupyter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverables\n",
    "Complete all the exercises below and turn in a write up in the form of a Jupyuter notebook, that is, an **.ipynb file**.\n",
    "The write up should include your code, answers to exercise questions, and plots of results.\n",
    "Submit the assignment on Canvas under \"Lab 9\", with this file (after your edits) as an attachment. \n",
    "\n",
    "Notes:\n",
    "\n",
    "1. You have to use this notebook and fill in answers inline. \n",
    "\n",
    "2. Please do not add or remove any cells (you can add cells while doing the homework but remove them before submission).\n",
    "\n",
    "3. In this notebook, we provide code templates for many of the exercises. They are intended to help with code re-use, since the exercises build on each other. Don't forget to include answers to questions that ask for natural language responses, i.e., in English, not code!\n",
    "\n",
    "4. We will test your code automatically, so in your submitted notebook function names must conform with the names requested by the questions. Also you should make sure we can execute your notebook by running \"Cell > Run all\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need Help? \n",
    "In case you need help with this assignment, please ask your questions on the designated channel for Lab 9 on Microsoft Teams. This way, you may receive assistance from the TA‚Äôs or your classmates (<b>DO NOT share your solution</b>) [Recommended]. \n",
    "<br/>If you need to include your solution in your question, please create a new chat with <b>all the TA‚Äôs</b>. In the new chat, add all the TA‚Äôs rather than sending your question to the TA‚Äôs separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaboration\n",
    "This assignment is to be done individually. Everyone should be getting a hands on experience in this course. You are free to discuss course material with fellow students, and we encourage you to use resources on the Internet to aid your understanding, but the work you turn in, including all code and answers, must be your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Get Started!\n",
    "===\n",
    "\n",
    "## Overview\n",
    "Unsupervised learning is the process of learning about the structure and relationships between samples in a dataset without the use of any ground truth labels. Unlike supervised learning models which require knowledge of the class structure of the data, unsupervised learning models are capable of learning directly from the data itself, without any class labels.\n",
    "\n",
    "One of the most common methods for unsupervised learning is called \"clustering\". Clustering is the process of parititoning a dataset into groups. Samples within each group or \"cluster\" are similar to each other in some respect. In a typical \"hard\" clustering, each sample belongs to a single cluster (i.e. Samples can not belong to more than one cluster). However, there are \"soft\" clustering algorithms which can allow for samples to belong to multiple clusters at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application\n",
    "In Parts 1 and 2 of this lab, we will apply two well-known clustering algorithms to cluster a dataset containing different types of cars. For each car, the dataset records different measurements such as:\n",
    "* MPG (Miles per-gallon)\n",
    "* Displacemenet\n",
    "* Horsepower\n",
    "* Weight\n",
    "* Acceleration\n",
    "\n",
    "In particular, we will apply the following two *unsupervised* clustering algorithms to this dataset:\n",
    "* K-Means\n",
    "* Agglomerative Clustering\n",
    "\n",
    "and evaluate how well these algorithms are capable of detecting the underlying class structure in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files\n",
    "\n",
    "Data files for this assignment are provided in the `Data` folder inside the ZIP archive.\n",
    "\n",
    "`Data/` includes the following files:\n",
    "\n",
    "* **auto-mpg.data-original**, Data for the \"Auto MPG\" dataset.\n",
    "* **train.fmat.txt**, Data from the MNIST digit dataset.\n",
    "* **ictrain.imat.txt**, Labels for the MNIST digit dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 [10 points]\n",
    "Load the file `auto-mpg.data` into a Pandas DataFrame called `data`.\n",
    "\n",
    "This dataset does have a few quirks:\n",
    "\n",
    "First, the dataset is whitespace delimited, you can use `pd.read_csv`'s `delim_whitespace` argument to handle this.\n",
    "\n",
    "Second, the missing values are encoded with a question mark `?`. To handle this, you can use the `na_values` argument from `pd.read_csv`. \n",
    "\n",
    "**NOTE:** Refer [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) for the full documentation of `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
      "0   18.0          8         307.0       130.0  3504.0          12.0   \n",
      "1   15.0          8         350.0       165.0  3693.0          11.5   \n",
      "2   18.0          8         318.0       150.0  3436.0          11.0   \n",
      "3   16.0          8         304.0       150.0  3433.0          12.0   \n",
      "4   17.0          8         302.0       140.0  3449.0          10.5   \n",
      "5   15.0          8         429.0       198.0  4341.0          10.0   \n",
      "6   14.0          8         454.0       220.0  4354.0           9.0   \n",
      "7   14.0          8         440.0       215.0  4312.0           8.5   \n",
      "8   14.0          8         455.0       225.0  4425.0          10.0   \n",
      "9   15.0          8         390.0       190.0  3850.0           8.5   \n",
      "10  15.0          8         383.0       170.0  3563.0          10.0   \n",
      "11  14.0          8         340.0       160.0  3609.0           8.0   \n",
      "12  15.0          8         400.0       150.0  3761.0           9.5   \n",
      "13  14.0          8         455.0       225.0  3086.0          10.0   \n",
      "14  24.0          4         113.0        95.0  2372.0          15.0   \n",
      "15  22.0          6         198.0        95.0  2833.0          15.5   \n",
      "16  18.0          6         199.0        97.0  2774.0          15.5   \n",
      "17  21.0          6         200.0        85.0  2587.0          16.0   \n",
      "18  27.0          4          97.0        88.0  2130.0          14.5   \n",
      "19  26.0          4          97.0        46.0  1835.0          20.5   \n",
      "20  25.0          4         110.0        87.0  2672.0          17.5   \n",
      "21  24.0          4         107.0        90.0  2430.0          14.5   \n",
      "22  25.0          4         104.0        95.0  2375.0          17.5   \n",
      "23  26.0          4         121.0       113.0  2234.0          12.5   \n",
      "24  21.0          6         199.0        90.0  2648.0          15.0   \n",
      "25  10.0          8         360.0       215.0  4615.0          14.0   \n",
      "26  10.0          8         307.0       200.0  4376.0          15.0   \n",
      "27  11.0          8         318.0       210.0  4382.0          13.5   \n",
      "28   9.0          8         304.0       193.0  4732.0          18.5   \n",
      "29  27.0          4          97.0        88.0  2130.0          14.5   \n",
      "30  28.0          4         140.0        90.0  2264.0          15.5   \n",
      "31  25.0          4         113.0        95.0  2228.0          14.0   \n",
      "32  25.0          4          98.0         NaN  2046.0          19.0   \n",
      "33  19.0          6         232.0       100.0  2634.0          13.0   \n",
      "34  16.0          6         225.0       105.0  3439.0          15.5   \n",
      "35  17.0          6         250.0       100.0  3329.0          15.5   \n",
      "36  19.0          6         250.0        88.0  3302.0          15.5   \n",
      "37  18.0          6         232.0       100.0  3288.0          15.5   \n",
      "38  14.0          8         350.0       165.0  4209.0          12.0   \n",
      "39  14.0          8         400.0       175.0  4464.0          11.5   \n",
      "40  14.0          8         351.0       153.0  4154.0          13.5   \n",
      "41  14.0          8         318.0       150.0  4096.0          13.0   \n",
      "42  12.0          8         383.0       180.0  4955.0          11.5   \n",
      "43  13.0          8         400.0       170.0  4746.0          12.0   \n",
      "44  13.0          8         400.0       175.0  5140.0          12.0   \n",
      "45  18.0          6         258.0       110.0  2962.0          13.5   \n",
      "46  22.0          4         140.0        72.0  2408.0          19.0   \n",
      "47  19.0          6         250.0       100.0  3282.0          15.0   \n",
      "48  18.0          6         250.0        88.0  3139.0          14.5   \n",
      "49  23.0          4         122.0        86.0  2220.0          14.0   \n",
      "50  28.0          4         116.0        90.0  2123.0          14.0   \n",
      "51  30.0          4          79.0        70.0  2074.0          19.5   \n",
      "52  30.0          4          88.0        76.0  2065.0          14.5   \n",
      "53  31.0          4          71.0        65.0  1773.0          19.0   \n",
      "54  35.0          4          72.0        69.0  1613.0          18.0   \n",
      "55  27.0          4          97.0        60.0  1834.0          19.0   \n",
      "56  26.0          4          91.0        70.0  1955.0          20.5   \n",
      "57  24.0          4         113.0        95.0  2278.0          15.5   \n",
      "58  25.0          4          97.5        80.0  2126.0          17.0   \n",
      "59  23.0          4          97.0        54.0  2254.0          23.5   \n",
      "\n",
      "    model year  origin                      car name  \n",
      "0           70       1     chevrolet chevelle malibu  \n",
      "1           70       1             buick skylark 320  \n",
      "2           70       1            plymouth satellite  \n",
      "3           70       1                 amc rebel sst  \n",
      "4           70       1                   ford torino  \n",
      "5           70       1              ford galaxie 500  \n",
      "6           70       1              chevrolet impala  \n",
      "7           70       1             plymouth fury iii  \n",
      "8           70       1              pontiac catalina  \n",
      "9           70       1            amc ambassador dpl  \n",
      "10          70       1           dodge challenger se  \n",
      "11          70       1            plymouth 'cuda 340  \n",
      "12          70       1         chevrolet monte carlo  \n",
      "13          70       1       buick estate wagon (sw)  \n",
      "14          70       3         toyota corona mark ii  \n",
      "15          70       1               plymouth duster  \n",
      "16          70       1                    amc hornet  \n",
      "17          70       1                 ford maverick  \n",
      "18          70       3                  datsun pl510  \n",
      "19          70       2  volkswagen 1131 deluxe sedan  \n",
      "20          70       2                   peugeot 504  \n",
      "21          70       2                   audi 100 ls  \n",
      "22          70       2                      saab 99e  \n",
      "23          70       2                      bmw 2002  \n",
      "24          70       1                   amc gremlin  \n",
      "25          70       1                     ford f250  \n",
      "26          70       1                     chevy c20  \n",
      "27          70       1                    dodge d200  \n",
      "28          70       1                      hi 1200d  \n",
      "29          71       3                  datsun pl510  \n",
      "30          71       1           chevrolet vega 2300  \n",
      "31          71       3                 toyota corona  \n",
      "32          71       1                    ford pinto  \n",
      "33          71       1                   amc gremlin  \n",
      "34          71       1     plymouth satellite custom  \n",
      "35          71       1     chevrolet chevelle malibu  \n",
      "36          71       1               ford torino 500  \n",
      "37          71       1                   amc matador  \n",
      "38          71       1              chevrolet impala  \n",
      "39          71       1     pontiac catalina brougham  \n",
      "40          71       1              ford galaxie 500  \n",
      "41          71       1             plymouth fury iii  \n",
      "42          71       1             dodge monaco (sw)  \n",
      "43          71       1      ford country squire (sw)  \n",
      "44          71       1           pontiac safari (sw)  \n",
      "45          71       1    amc hornet sportabout (sw)  \n",
      "46          71       1           chevrolet vega (sw)  \n",
      "47          71       1              pontiac firebird  \n",
      "48          71       1                  ford mustang  \n",
      "49          71       1            mercury capri 2000  \n",
      "50          71       2                     opel 1900  \n",
      "51          71       2                   peugeot 304  \n",
      "52          71       2                     fiat 124b  \n",
      "53          71       3           toyota corolla 1200  \n",
      "54          71       3                   datsun 1200  \n",
      "55          71       2          volkswagen model 111  \n",
      "56          71       1              plymouth cricket  \n",
      "57          72       3         toyota corona hardtop  \n",
      "58          72       1            dodge colt hardtop  \n",
      "59          72       2             volkswagen type 3  \n"
     ]
    }
   ],
   "source": [
    "columns = [\"mpg\",\"cylinders\",\"displacement\",\"horsepower\",\"weight\",\"acceleration\",\"model year\",\"origin\",\"car name\"]\n",
    "data = pd.read_csv(\"auto-mpg.data\", header=None,names=columns, delim_whitespace=True, na_values = \"?\") \n",
    "print(data.head(60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 [5 points]\n",
    "\n",
    "For our experiments, we will only use a subset of this data.\n",
    "\n",
    "Subset `data` to use only the following 3 columns:\n",
    "* `horsepower`\n",
    "* `weight` \n",
    "* `acceleration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     horsepower  weight  acceleration\n",
      "0         130.0  3504.0          12.0\n",
      "1         165.0  3693.0          11.5\n",
      "2         150.0  3436.0          11.0\n",
      "3         150.0  3433.0          12.0\n",
      "4         140.0  3449.0          10.5\n",
      "..          ...     ...           ...\n",
      "393        86.0  2790.0          15.6\n",
      "394        52.0  2130.0          24.6\n",
      "395        84.0  2295.0          11.6\n",
      "396        79.0  2625.0          18.6\n",
      "397        82.0  2720.0          19.4\n",
      "\n",
      "[398 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data = data[[\"horsepower\", \"weight\", \"acceleration\" ]]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 [5 points]\n",
    "\n",
    "We will not be able to use samples that have missing values for one or more of the columns.\n",
    "\n",
    "Drop **any** rows in `data` which have **one or more** missing values.\n",
    "\n",
    "**HINT:** [Documentation for DataFrame.dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    horsepower  weight  acceleration\n",
      "0        130.0  3504.0          12.0\n",
      "1        165.0  3693.0          11.5\n",
      "2        150.0  3436.0          11.0\n",
      "3        150.0  3433.0          12.0\n",
      "4        140.0  3449.0          10.5\n",
      "5        198.0  4341.0          10.0\n",
      "6        220.0  4354.0           9.0\n",
      "7        215.0  4312.0           8.5\n",
      "8        225.0  4425.0          10.0\n",
      "9        190.0  3850.0           8.5\n",
      "10       170.0  3563.0          10.0\n",
      "11       160.0  3609.0           8.0\n",
      "12       150.0  3761.0           9.5\n",
      "13       225.0  3086.0          10.0\n",
      "14        95.0  2372.0          15.0\n",
      "15        95.0  2833.0          15.5\n",
      "16        97.0  2774.0          15.5\n",
      "17        85.0  2587.0          16.0\n",
      "18        88.0  2130.0          14.5\n",
      "19        46.0  1835.0          20.5\n",
      "20        87.0  2672.0          17.5\n",
      "21        90.0  2430.0          14.5\n",
      "22        95.0  2375.0          17.5\n",
      "23       113.0  2234.0          12.5\n",
      "24        90.0  2648.0          15.0\n",
      "25       215.0  4615.0          14.0\n",
      "26       200.0  4376.0          15.0\n",
      "27       210.0  4382.0          13.5\n",
      "28       193.0  4732.0          18.5\n",
      "29        88.0  2130.0          14.5\n",
      "30        90.0  2264.0          15.5\n",
      "31        95.0  2228.0          14.0\n",
      "33       100.0  2634.0          13.0\n",
      "34       105.0  3439.0          15.5\n",
      "35       100.0  3329.0          15.5\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "print(data.head(35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 [5 points]\n",
    "Since these variables are on different scales (`weight` values are much larger than values for `horsepower` or `acceleration`), we need to normalize each column.\n",
    "\n",
    "Use the `StandardScaler` object from `scikit-learn` to normalize each column of `data`.\n",
    "\n",
    "[StandardScaler documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "\n",
    "**NOTE:** When you are finished, make sure that `data` is still a DataFrame! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.66413273  0.62054034 -1.285258  ]\n",
      " [ 1.57459447  0.84333403 -1.46672362]\n",
      " [ 1.18439658  0.54038176 -1.64818924]\n",
      " ...\n",
      " [-0.53247413 -0.80463202 -1.4304305 ]\n",
      " [-0.66254009 -0.41562716  1.11008813]\n",
      " [-0.58450051 -0.30364091  1.40043312]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: $k$-means Clustering\n",
    "\n",
    "The $k$-means algorithm is a popular and relatively simple algorithm for clustering. To initialize the algorithm, the user must first specify $k$ which represents the number of clusters to be generated. Once $k$ is chosen, the algorithm will intialize $k$ centroids, which will represent the centers of the $k$ clusters. \n",
    "\n",
    "### $k$-means algorithm:\n",
    "1. For each sample, calculate the distance between that sample and **each** of the $k$ centroids.\n",
    "2. Assign each of the samples the \"label\" of the *nearest* centroid.\n",
    "3. Update each of the $k$ centroids by setting it equal to the the **mean** of the samples which have that centroid's label. \n",
    "\n",
    "This process is performed iteratively until some stopping criteria is met. \n",
    "\n",
    "The below figure shows an example of a $k$-means clustering for $k=3$.\n",
    "\n",
    "![k-means clustering](imgs/k-means.gif)\n",
    "*Image Credit: [Wikipedia Commons](https://commons.wikimedia.org/wiki/File:K-means_convergence.gif)*\n",
    "\n",
    "## Determining the Best $k$:\n",
    "The $k$-means algorithm requires that the user choose $k$, the number of cluster centroids. However, this causes a chicken-and-egg problem! If we are trying to perform *unsupervised* learning we **don't know** how many clusters we should use in the first place! We can try clustering with multiple values for $k$, but we need a way to pick the best $k$ out of the candidates that we try.\n",
    "\n",
    "In order to find the $k$ that most agrees with the data, we will use a metric known as Silhouette Score.\n",
    "\n",
    "## Silhouette Score\n",
    "Silhouette Score is a metric that may be used to measure how well a set of cluster labels \"agree\" with the distribution of the data.\n",
    "\n",
    "Silhouette is defined by three equations:\n",
    "\n",
    "$$ a(i) = \\frac{1}{|C_i| - 1}\\sum_{j \\in C_i,i\\neq j}{d(i,j)} $$\n",
    "\n",
    "$$ b(i) = \\min_{k \\neq i} \\frac{1}{|C_k|} \\sum_{j \\in C_k}{d(i,j)}$$\n",
    "\n",
    "$$ s(i) = \\frac{b(i) - a(i)}{\\max{\\{a(i),b(i)\\}}} $$\n",
    "\n",
    "* The first equation $a(i)$ calculates the average distance from sample $i$ to all other points within the same cluster as $i$.\n",
    "* The second equation $b(i)$ calculates the average distance from sample $i$ to the points in the second-closest cluster to $i$. \n",
    "* The third equation $s(i)$ combines $a(i)$ and $b(i)$ into a single metric.\n",
    "\n",
    "Intuitively, $a(i)$ measures how close sample $i$ is to the other points in the same cluster. Low values for $i$ indicate that the $i$ is very close to the other points in the cluster, indicating that the cluster is dense.\n",
    "\n",
    "$b(i)$ measures the distance between $i$'s \"home\" cluster and the second-closest cluster to $i$. If this value is large, than $i$ is well-clustered, since it is much closer to points within its own cluster than to points in the second closest cluster. \n",
    "\n",
    "$s(i)$ arranges $a(i)$ and $b(i)$ into a normalized term in the interval $[-1,1]$. A value of $s(i) \\approx 1$, indicates a \"good\" clustering for $i$, since $s(i)$ will be close to one when:\n",
    "* $a(i)$ is small ($i$ is close to its neighbor points)\n",
    "\n",
    "and/or\n",
    "* $b(i)$ is large ($i$ is well-separated from the neighboring cluster). \n",
    "\n",
    "Similarly, a value of $s(i) \\approx -1$ indicates the *worst possible clustering* for $i$, since either:\n",
    "* $a(i)$ is very big ($i$ is not close to its neighbors)\n",
    "\n",
    "and/or\n",
    "* $b(i)$ is very small ($i$ is very close to a neighboring cluster).\n",
    "\n",
    "The Silhouette coefficient $s(i)$ shown above is calculated once for each sample being clustered. Taking the average of $s(i)$ for all clustered samples will give an overall measure of cluster \"agreement\" with the data. \n",
    "\n",
    "In the next section, we will perform multiple $k$-means clustering operations, and evaluate each one using the Silhouette coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a $k$-means model using `KMeans` from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_obj = KMeans(n_clusters=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `km_obj` model we created above, we can fit the model and then retrieve the cluster labeling for each sample using the `fit_predict` method of `km_obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = km_obj.fit_predict(data)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 [15 points]\n",
    "\n",
    "For $k = [2,15]$, fit a $k$-means model with $k$ centroids.\n",
    "\n",
    "Record the labels provided by $k$-means in the dictionary `labels_k`, such that `labels_k[i]` holds the array of labels returned from the $k$-means fit with $i$ centroids.\n",
    "\n",
    "Your `labels_k` dictionary should look something like this:\n",
    "\n",
    "```\n",
    "{2: array([...]),\n",
    " 3: array([...]),\n",
    " ...\n",
    " 15: array([...])}\n",
    "```\n",
    "\n",
    "Where each `array([...])` contains a set of $k$-means labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_k = dict()\n",
    "# TODO: Answer Q5\n",
    "for i in range(2, 16):\n",
    "    km_obj = KMeans(n_clusters = i)\n",
    "    labels_k[i] = km_obj.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we created a $k$-means fit with $k=5$ and stored the resulting labeling in `labels`. To calculate the average Silhouette coefficient for our entire dataset, we can use the `silhouette_score` function from `scikit-learn`.\n",
    "\n",
    "`silhouette_score` expects to be called like `silhouette_score(data,labels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for K=5: 0.358\n",
      "0.35792807712116814\n"
     ]
    }
   ],
   "source": [
    "print(\"Silhouette score for K=5: %0.3f\" % silhouette_score(data,labels))\n",
    "sil_score = silhouette_score(data,labels)\n",
    "print(sil_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 [15 points]\n",
    "\n",
    "Great! Now that we have a set of $k$-means labelings for $k = [2,15]$, we can evaluate each one using `silhouette_score` to obtain the \"best\" fitting $k$ for our model.\n",
    "\n",
    "We will use the `labels_k` dictionary you created above to plot the Silhouette score for each $k$.\n",
    "\n",
    "### 6.1:\n",
    "Create a line plot which has $k$ on the X-axis, and the calculated Silhouette score on the Y-axis (refer to the above cell for how to calculate Silhouette score given a set of labels).\n",
    "\n",
    "The plot should show a line along with markers at each point. \n",
    "\n",
    "Be sure to label your axes and give the chart a title!\n",
    "\n",
    "### 6.2:\n",
    "Based on what we saw with Silhouette coefficient in the previous section, which value of $k$ provides the \"best\" (as defined by silhouette score) agreement between the clusters and the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Silhouette_score')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO:\n",
    "# Answer 6.1 here.\n",
    "y_ax = []\n",
    "x_ax=[]\n",
    "for x in range(2,16,1):\n",
    "    y_ax.append(x)\n",
    "    x_ax.append(silhouette_score(data,labels_k[x]))\n",
    "plt.plot(x_ax, y_ax, marker ='o', color='b')\n",
    "plt.xlabel('k_value')\n",
    "plt.ylabel('Silhouette_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Answer 6.2 here.\n",
    "#k=2 (silhouette score is 0.57116) is the best silhouette score obtained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize some of these clustering results. \n",
    "\n",
    "We can use the `pairplot` function from the `seaborn` library to produce a grid of scatter plots between each pair of variables.\n",
    "\n",
    "The `plot_kws={\"s\":10}` argument sets the size of the points in the scatter plot to be `10`. This is because sometimes larger point sizes can make it difficult to see separation between groups. You may change this to be larger or smaller if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = data.copy()\n",
    "sns.pairplot(v_data,plot_kws={\"s\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `hue` argument to `pairplot`, we can select one of the columns to be the color for the plot. This is handy for visualizing clustering results.\n",
    "\n",
    "First, let's visualize the clustering result for $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIS_K = 2\n",
    "v_data[\"labels\"] = labels_k[VIS_K]\n",
    "sns.pairplot(data=v_data,hue=\"labels\",plot_kws={\"s\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 [10 points]\n",
    "In a few sentences, use the above plot to discuss how the clustering algorithm has partitioned our data.\n",
    "\n",
    "Here are some examples of questions you might discuss in your answer:\n",
    "\n",
    "* What do the members of each cluster have in common?\n",
    "* Are there any variables that appear to be important/not important for cluster separation?\n",
    "\n",
    "You can also try setting the `VIS_K` variable to a different value, to visualize the cluster separation for other values of $k$. \n",
    "\n",
    "* What happens to the clusters as you increase the value of $k$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: Answer Q7 here. (It was working before and now the code doesnt run. I dont know why?)\n",
    "\n",
    "\n",
    "What do the members of each cluster have in common?\n",
    "Both clusters seem to have overlapping density plots at diaglonal grid\n",
    "\n",
    "\n",
    "Are there any variables that appear to be important/not important for cluster separation?\n",
    "Weight and horsepower are positively correlated and have a good relationship.\n",
    "Horsepower and acceleration is negatively correlated but they have a relatively good relationship.\n",
    "Weight and acceleration do not have a strong relationship. \n",
    "\n",
    "\n",
    "What happens to the clusters as you increase the value of  ùëò k?\n",
    "When VIS_K value is increased, the number of clusters increase and we can see the distribution based on the k value we chose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Agglomerative Clustering (Extra Credit)\n",
    "\n",
    "## IMPORTANT:\n",
    "This section (Questions 8, 9, and 10) gives you the opportunity to earn up to 20 extra credit points! This section is optional, so if you do not want the extra credit, just proceed to **Part 3: Autoencoder**.\n",
    "\n",
    "## Overview:\n",
    "\n",
    "Agglomerative clustering is a method for bottom-up hierarchical clustering. In Agglomerative clustering, each sample starts in its own \"cluster\". A distance metric and linkage criterion are used to determine which clusters to merge with each other at each step. Intuitively, pairs of clusters which are very similar to each other may be merged.\n",
    "\n",
    "Since each sample starts in its own cluster and is merged into larger clusters, the clustering result may be easily visualized as a \"tree\" of hierarchical clusters. \n",
    "\n",
    "![hierarchical clustering result](imgs/hierarchical_cluster.png)\n",
    "*Image Credit: [Wikipedia](https://en.wikipedia.org/wiki/Hierarchical_clustering#/media/File:Hierarchical_clustering_simple_diagram.svg)*\n",
    "\n",
    "To obtain a clustering result for $k$ clusters, one just needs to cut the \"tree\" at the appropriate point. \n",
    "\n",
    "In the following section, we will also apply Agglomerative clustering as a technique for clustering our auto data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the prior section, we can create a `AgglomerativeClustering` object to perform clustering for us. The `n_clusters` parameter controls the value for number of clusters $k$.\n",
    "\n",
    "Here we create an `AgglomerativeClustering` object and call it `agg_obj`, then use the `fit_predict` method to fit it and produce a label set for our data.\n",
    "\n",
    "Finally, we print out the Silhouette score using `silhouette_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agglomerative Clustering Silhouette score for K=5: 0.329\n"
     ]
    }
   ],
   "source": [
    "agg_obj = AgglomerativeClustering(n_clusters=5)\n",
    "agg_labels = agg_obj.fit_predict(data)\n",
    "print(\"Agglomerative Clustering Silhouette score for K=5: %0.3f\" % silhouette_score(data,agg_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8 [10 points]\n",
    "\n",
    "For $k = [2,15]$, fit a Agglomerative Clustering model with $k$ clusters and store the results in the dictionary `agg_labels_k`.\n",
    "\n",
    "The dictionary entry `agg_labels_k[i]` should hold the array of labels returned from the clustering fit with $i$ clusters.\n",
    "\n",
    "Your `agg_labels_k` dictionary should look something like this:\n",
    "\n",
    "```\n",
    "{2: array([...]),\n",
    " 3: array([...]),\n",
    " ...\n",
    " 15: array([...])}\n",
    "```\n",
    "\n",
    "Where each `array([...])` contains a set of cluster labels.\n",
    "\n",
    "**NOTE:** You can resue most of your code from Q5!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_labels_k = dict()\n",
    "# TODO: Answer Q8 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9 [5 points]\n",
    "\n",
    "Using your `agg_labels_k` dictionary, create a line plot which has $k$ on the X-axis, and the calculated Silhouette score on the Y-axis (refer to the above cell for how to calculate Silhouette score given a set of labels).\n",
    "\n",
    "The plot should show a line along with markers at each point. \n",
    "\n",
    "Be sure to label your axes and give the chart a title!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Answer Q9 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10 [5 points]\n",
    "How do you think that Agglomerative Clustering performed relative to $k$-means?\n",
    "\n",
    "Since the clustering algorithms differ in how they perform clustering (centroid-based vs merging pairs of clusters), are there any situations where it might be better to use one algorithm over the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer Q10 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Autoencoder\n",
    "\n",
    "For high-dimensional datasets, clustering based on raw data may not be optimal due to the curse of dimensionality, which shows that distance comparisons between samples become less meaningful as the dimensionality of the data increases. \n",
    "\n",
    "One solution to this is to use a dimensionality reduction technique before applying clustering. \n",
    "\n",
    "Autoenocoders are a neural network architecture which may be used to perform dimensionality reduction. These models are trained to reconstruct their inputs from a \"constrained\" view of the data. The autoencoder must learn features of the data in order to compress the data into a lower dimensional representation.\n",
    "\n",
    "![Autoencoder](imgs/Autoencoder_structure.png)\n",
    "*Image Credit: [Wikipedia](https://en.wikipedia.org/wiki/Autoencoder#/media/File:Autoencoder_structure.png)*\n",
    "\n",
    "In this section we will build a simple autoencoder model and apply it to learn a featurization of the well-known MNIST handwritten digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Required to avoid a kernel crash on MacOS\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we define the Encoder and Decoder portions of our model. Our model will have 2 convolutional layers, each followed by a max-pool layer.\n",
    "\n",
    "At the end, we flatten the output to create a feature vector of 16 dimensions per-sample (a large reduction from the original 768 dimensions per-sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input((28,28,1))\n",
    "layer_outputs = [input_layer]\n",
    "# Build Encoder layers\n",
    "enc_conv_1 = keras.layers.Conv2D(filters=8,kernel_size=(3,3),activation=\"relu\",padding=\"same\",name=\"enc_conv_1\")(input_layer)\n",
    "enc_mp_1 = keras.layers.MaxPool2D(pool_size=2,name=\"enc_mp_1\")(enc_conv_1)\n",
    "enc_conv_2 = keras.layers.Conv2D(filters=16,kernel_size=(3,3),activation=\"relu\",padding=\"same\",name=\"enc_conv_2\")(enc_mp_1)\n",
    "enc_mp_2 = keras.layers.MaxPool2D(pool_size=2,name=\"enc_mp_2\")(enc_conv_2)\n",
    "enc_flat = keras.layers.Flatten(name=\"enc_flat\")(enc_mp_2)\n",
    "enc_dense = keras.layers.Dense(units=16,name=\"enc_dense\")(enc_flat)\n",
    "# Build Decoder layers\n",
    "decoder_input = enc_dense\n",
    "dec_dense = keras.layers.Dense(units=enc_flat.shape[-1],name=\"dec_dense\")(decoder_input)\n",
    "dec_reshape = keras.layers.Reshape(enc_mp_2.shape[1:],name=\"dec_reshape\")(dec_dense)\n",
    "dec_upsmp_2 = keras.layers.UpSampling2D(name=\"dec_upsmp_2\")(dec_reshape)\n",
    "dec_deconv_2 = keras.layers.Conv2DTranspose(filters=16,kernel_size=(3,3),activation=\"relu\",padding=\"same\",name=\"dec_deconv_2\")(dec_upsmp_2)\n",
    "dec_upsmp_1 = keras.layers.UpSampling2D(name=\"dec_upsmp_1\")(dec_deconv_2)\n",
    "dec_deconv_1 = keras.layers.Conv2DTranspose(filters=1,kernel_size=(3,3),activation=\"relu\",padding=\"same\",name=\"dec_deconv_1\")(dec_upsmp_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built all of the individual layers, we create a new `Model` and pass it the inputs `input_layer` and outputs `dec_deconv_1` for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "enc_conv_1 (Conv2D)          (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "enc_mp_1 (MaxPooling2D)      (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "enc_conv_2 (Conv2D)          (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "enc_mp_2 (MaxPooling2D)      (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "enc_flat (Flatten)           (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "enc_dense (Dense)            (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dec_dense (Dense)            (None, 784)               13328     \n",
      "_________________________________________________________________\n",
      "dec_reshape (Reshape)        (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "dec_upsmp_2 (UpSampling2D)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dec_deconv_2 (Conv2DTranspos (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dec_upsmp_1 (UpSampling2D)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dec_deconv_1 (Conv2DTranspos (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 29,601\n",
      "Trainable params: 29,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs=input_layer,outputs=dec_deconv_1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11 [5 points]\n",
    "\n",
    "In a few sentences, give your interpretation of what the architecture shown above is doing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Answer Q11 here\n",
    "Model groups layers into an object with training and inference features.Keras model represents the actual neural network model. Keras provides a two mode to create the model, simple and easy to use Sequential API as well as more flexible and advanced Functional API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12 [10 points]\n",
    "Now we need to load in the MNIST data:\n",
    "\n",
    "In the next cells:\n",
    "\n",
    "1. Load `train.fmat.txt` and `ictrain.imat.txt` to numpy arrays called `imgs` and `labels` respectively.\n",
    "2. Transpose `imgs` and `labels` so that the labels are the first dimension.\n",
    "3. Scale the values in `imgs` to fall between 0 and 1. \n",
    "4. Reshape the images from their flattened `768`-dimensional format so that each image is shape `28,28,1`. (i.e. your `imgs` array is shape `4000,28,28,1`).\n",
    "\n",
    "**HINT:** You have done all of these procedures before for Lab 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Answer Q12\n",
    "imgs = np.loadtxt(\"train.fmat.txt\")\n",
    "labels = np.loadtxt(\"ictrain.imat.txt\")\n",
    "imgs = imgs.T\n",
    "imgs = (imgs- np.min(imgs))/(np.max(imgs) - np.min(imgs))\n",
    "imgs = imgs.reshape(imgs.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases.\n",
    "assert(imgs.shape[0] == 4000)\n",
    "assert(labels.shape[0] == 4000)\n",
    "assert(imgs.shape == (4000,28,28,1))\n",
    "assert(imgs.max() <= 1.0)\n",
    "assert(imgs.min() >= 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train our model by calling `model.compile` to compile the model, and `model.fit` to train the model with our data.\n",
    "\n",
    "Notice that because this is an autoencoder structure, both the inputs *and* outputs are `imgs`. There are no labels!\n",
    "\n",
    "**NOTE:** For the sake of time, we will only train for 10 epochs. (10 epochs runs in roughly 1 minute on a typical PC, but if this is taking too long for you, you may reduce the number of epochs.)\n",
    "\n",
    "Alternatively, if you have a fast computer and/or a GPU, you might be able to train for more than 10 epochs, to see if you can get better performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 13s 3ms/sample - loss: 0.0419\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 9s 2ms/sample - loss: 0.0215\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 9s 2ms/sample - loss: 0.0180\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 9s 2ms/sample - loss: 0.0164\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 9s 2ms/sample - loss: 0.0154\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 9s 2ms/sample - loss: 0.0147\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 9s 2ms/sample - loss: 0.0141\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 9s 2ms/sample - loss: 0.0138\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 9s 2ms/sample - loss: 0.0134\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 9s 2ms/sample - loss: 0.0131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4d3e1390>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(imgs,imgs,epochs=10,batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained the model, lets view our model's \"predictions\" for the input images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = model.predict(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q13 [10 points]\n",
    "`imgs` contains the original data images, and `pred_images` contains our model's \"predicted\" images for each of the images in `imgs`. \n",
    "\n",
    "Choose 2 images from `imgs` and use `plt.imshow` to plot them along with their corresponding predicted images from `pred_images`.\n",
    "\n",
    "**HINT:** The indices of the first dimensions are the same, so `pred_images[i]` refers to the predicted image for image `imgs[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'predicted')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(ncols=2)\n",
    "ax[0].imshow(imgs[0])\n",
    "ax[0].set_title(\"actual\")\n",
    "ax[1].imshow(pred_images[0])\n",
    "ax[1].set_title(\"predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try clustering with our Autoencoder's featurized data. First we need to get the feature vectors for our data!\n",
    "\n",
    "In order to get the predictions from the \"latent space\" of our model, we need to create a new Keras model to represent just the Encoder portion of the autencoder. This model will uses `input_layer` for the input and `enc_dense` for the output, since `enc_dense` is our \"latent features\" layer. If this is confusing, refer back to the `model.summary()` call which shows the full architecture of the model.\n",
    "\n",
    "Our new model `latent_model` will help with getting the latent features. Note that we don't call `fit()` on this model. Since we are using the same layers that we used for our original `model`, the paramters for this subset of the model are already trained! We can simply call `latent_model.predict()` to get the feature vectors for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 16)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_model = keras.Model(inputs=input_layer,outputs=enc_dense)\n",
    "latent_features = latent_model.predict(imgs)\n",
    "latent_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `latent_features` holds 16-dimensional feature vectors for each of our 4000 samples.\n",
    "We can try clustering on these latent features to see how well the dimensionality reduction has worked!\n",
    "\n",
    "Since we have ground-truth labels for this dataset, we can evaluate performance directly using these labels instead of using Silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q14 [5 points]\n",
    "\n",
    "Run a $k$-means clustering on `latent_features` using $k=10$, and record the labels as `img_clust_labels`.\n",
    "\n",
    "Just as before, you can use the `KMeans` object from `scikit-learn` to do this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Q14\n",
    "km_obj = KMeans(n_clusters=10)\n",
    "img_clust_labels = km_obj.fit_predict(latent_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will evaluate performance using adjusted rand index (ARI). ARI is a measure similar to accuracy, where larger values indicate better performance. An ARI of 1.0 indicates perfect (100%) accuracy, and a value close to 0 indicates 0% accuracy.\n",
    "\n",
    "You can learn more about Adjusted Rand Index here: [ARI Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4000, 392]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-3297cf6d3012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ARI for CAE featurized MNIST: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0madjusted_rand_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_clust_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/cluster/_supervised.py\u001b[0m in \u001b[0;36madjusted_rand_score\u001b[0;34m(labels_true, labels_pred)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_clusterings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/cluster/_supervised.py\u001b[0m in \u001b[0;36mcheck_clusterings\u001b[0;34m(labels_true, labels_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m         raise ValueError(\n\u001b[1;32m     60\u001b[0m             \"labels_pred must be 1D: shape is %r\" % (labels_pred.shape,))\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4000, 392]"
     ]
    }
   ],
   "source": [
    "print(\"ARI for CAE featurized MNIST: %0.3f\" % adjusted_rand_score(img_clust_labels,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q15 [5 points]\n",
    "How well did the AE model do on this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer Q15 here.\n",
    "#the AE model did not do well based on the ARI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Save and submit your notebook on Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
